{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vision-Transformer-Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9MCNjzaalqIkqKB8u4uFH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fgokmenoglu/PYTORCH/blob/main/Vision_Transformer_Ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-e5pbKN8HoX",
        "outputId": "934a24d4-a0a6-4f43-9fb2-62a5687b434e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 5 loss: 410.23\n",
            "Epoch 2 / 5 loss: 390.20\n",
            "Epoch 3 / 5 loss: 384.24\n",
            "Epoch 4 / 5 loss: 374.24\n",
            "Epoch 5 / 5 loss: 372.16\n",
            "Test loss: 61.88\n",
            "Test accuracy: 87.67%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class MyViT(nn.Module):\n",
        "  def __init__(self, input_shape, n_patches=7, hidden_d=8, n_heads=2, out_d=10):\n",
        "    # Super constructor\n",
        "    super(MyViT, self).__init__()\n",
        "\n",
        "    # Input and patches sizes\n",
        "    self.input_shape = input_shape # w.r.t images --> (N, C, H, W)\n",
        "    self.n_patches = n_patches # breaking image in n_patches x n_patches\n",
        "    self.n_heads= n_heads\n",
        "    assert input_shape[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
        "    assert input_shape[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
        "    self.patch_size = (input_shape[1] / n_patches, input_shape[2] / n_patches)\n",
        "    self.hidden_d = hidden_d\n",
        "\n",
        "    # Step 1: Linear mapper\n",
        "    self.input_d = int(input_shape[0] * self.patch_size[0] * self.patch_size[1])\n",
        "    self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
        "\n",
        "    # Step 2: Classification token\n",
        "    self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
        "\n",
        "    # Step 3: Positional embedding\n",
        "    # Check inside forward function\n",
        "    \n",
        "    # Step 4a: Layer normalization 1\n",
        "    self.ln1 = nn.LayerNorm((self.n_patches ** 2 + 1, self.hidden_d))\n",
        "\n",
        "    # Step 4b: Multi-head SeÅŸf Attention (MSA) and classification token\n",
        "    self.msa = MyMSA(self.hidden_d, n_heads)\n",
        "\n",
        "    # Step 5a: Layer normalization 2\n",
        "    self.ln2 = nn.LayerNorm((self.n_patches ** 2 + 1, self.hidden_d))\n",
        "\n",
        "    # Step 5b: Encoder MLP\n",
        "    self.enc_mlp = nn.Sequential(nn.Linear(self.hidden_d, self.hidden_d), nn.ReLU())\n",
        "\n",
        "    # Step 6: Classification MLP\n",
        "    self.mlp = nn.Sequential(nn.Linear(self.hidden_d, out_d), nn.Softmax(dim=-1))\n",
        "\n",
        "  def forward(self, images):\n",
        "    # Divide images into patches\n",
        "    n, c, w, h = images.shape\n",
        "    patches = images.reshape(n, self.n_patches ** 2, self.input_d)\n",
        "\n",
        "    # Run linear layer for tokenization\n",
        "    tokens = self.linear_mapper(patches)\n",
        "\n",
        "    # Add classification token to the tokens\n",
        "    tokens = torch.stack([torch.vstack((self.class_token, tokens[ii])) for ii in range(len(tokens))])\n",
        "\n",
        "    # Add positional embedding\n",
        "    tokens += get_positional_embeddings(self.n_patches ** 2 + 1, self.hidden_d).repeat(n, 1, 1)\n",
        "\n",
        "    # TRANFORMER ENCODING BEGINS #\n",
        "    # Run layer normalization, MSA and residual connection\n",
        "    out = tokens + self.msa(self.ln1(tokens))\n",
        "\n",
        "    # Run layer normalization, MSA and residual connection\n",
        "    out = out + self.enc_mlp(self.ln2(out))\n",
        "    # TRANSFORMER ENCODING ENDS\n",
        "\n",
        "    # Get the classification\n",
        "    out = out[:, 0]\n",
        "\n",
        "    return self.mlp(out)\n",
        "\n",
        "class MyMSA(nn.Module):\n",
        "  def __init__(self, d, n_heads=2):\n",
        "    super(MyMSA, self).__init__()\n",
        "    self.d = d\n",
        "    self.n_heads = n_heads\n",
        "\n",
        "    assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
        "\n",
        "    d_head = int(d / n_heads)\n",
        "    self.q_mappings = [nn.Linear(d_head, d_head) for _ in range(self.n_heads)]\n",
        "    self.k_mappings = [nn.Linear(d_head, d_head) for _ in range(self.n_heads)]\n",
        "    self.v_mappings = [nn.Linear(d_head, d_head) for _ in range(self.n_heads)]\n",
        "    self.d_head = d_head\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, sequences):\n",
        "    # sequence had shape --> (N, seq_length, token_dim)\n",
        "    # reshaped           --> (N, seq_length, n_heads, token_dim / n_heads)\n",
        "    # came back to       --> (N, seq_length, item_dim) through concatenation\n",
        "\n",
        "    result = []\n",
        "\n",
        "    for sequence in sequences:\n",
        "      seq_result = []\n",
        "\n",
        "      for head in range(self.n_heads):\n",
        "        q_mapping = self.q_mappings[head]\n",
        "        k_mapping = self.k_mappings[head]\n",
        "        v_mapping = self.v_mappings[head]\n",
        "\n",
        "        seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
        "        q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
        "\n",
        "        attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
        "        seq_result.append(attention @ v)\n",
        "      \n",
        "      result.append(torch.hstack(seq_result))\n",
        "\n",
        "    return torch.cat([torch.unsqueeze(r, dim=0) for r in result])\n",
        "\n",
        "def get_positional_embeddings(sequence_length, d):\n",
        "  result = torch.ones(sequence_length, d)\n",
        "\n",
        "  for ii in range(sequence_length):\n",
        "    \n",
        "    for jj in range(d):\n",
        "      result[ii][jj] = np.sin(ii / (10000 ** (jj / d))) if jj % 2 == 0 else np.cos(ii / (10000 ** ((jj - 1) / d)))\n",
        "\n",
        "  return result\n",
        "\n",
        "def main():\n",
        "  # Loading data\n",
        "  transform = ToTensor()\n",
        "\n",
        "  train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n",
        "  test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n",
        "\n",
        "  train_loader = DataLoader(train_set, shuffle=True, batch_size=16)\n",
        "  test_loader = DataLoader(test_set, shuffle=False, batch_size=16)\n",
        "\n",
        "  # Defining model and training options\n",
        "  model = MyViT((1, 28, 28), n_patches=7, hidden_d=8, n_heads=2, out_d=10)\n",
        "  N_EPOCHS = 5\n",
        "  LR = 0.01\n",
        "\n",
        "  # Training loop\n",
        "  optimizer = Adam(model.parameters(), lr=LR)\n",
        "  criterion = CrossEntropyLoss()\n",
        "  \n",
        "  for epoch in range(N_EPOCHS):\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "      x, y = batch\n",
        "      y_hat = model(x)\n",
        "      loss = criterion(y_hat, y) / len(x)\n",
        "      train_loss += loss.item()\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} / {N_EPOCHS} loss: {train_loss:.2f}\")\n",
        "\n",
        "    # Testing loop\n",
        "  correct, total = 0, 0\n",
        "  test_loss = 0.0\n",
        "\n",
        "  for batch in test_loader:\n",
        "    x, y = batch\n",
        "    y_hat = model(x)\n",
        "    loss = criterion(y_hat, y)\n",
        "    test_loss += loss / len(x)\n",
        "    correct += torch.sum(torch.argmax(y_hat, dim=1) == y).item()\n",
        "    total += len(x)\n",
        "\n",
        "  print(f\"Test loss: {test_loss:.2f}\")\n",
        "  print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}
